{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLA-ProtBERT Demo\n",
    "\n",
    "This notebook demonstrates how to use the HLA-ProtBERT library to encode HLA alleles with pre-trained ProtBERT models.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The HLA-ProtBERT library allows you to:\n",
    "- Encode HLA alleles into high-dimensional protein embeddings\n",
    "- Find similar alleles based on embedding similarity\n",
    "- Compare different alleles\n",
    "- Use these embeddings for downstream tasks like clinical prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:56:29,407 - src.utils.logging - INFO - Logging initialized (level=INFO)\n",
      "Project directory: /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert\n",
      "Sequence file: /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/processed/hla_sequences.pkl\n",
      "Embeddings directory: /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import modules\n",
    "notebook_dir = Path().resolve()\n",
    "project_dir = notebook_dir.parent\n",
    "sys.path.insert(0, str(project_dir))\n",
    "\n",
    "# Import our modules\n",
    "from src.models.encoders.protbert import ProtBERTEncoder\n",
    "from src.utils.logging import setup_logging\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging(level=\"INFO\")\n",
    "\n",
    "# Set paths\n",
    "data_dir = project_dir / \"data\"\n",
    "sequence_file = data_dir / \"processed\" / \"hla_sequences.pkl\"\n",
    "embeddings_dir = data_dir / \"embeddings\"\n",
    "\n",
    "print(f\"Project directory: {project_dir}\")\n",
    "print(f\"Sequence file: {sequence_file}\")\n",
    "print(f\"Embeddings directory: {embeddings_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the ProtBERT Encoder\n",
    "\n",
    "Now we'll initialize the ProtBERT encoder that will convert HLA allele sequences into embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:56:29,413 - src.models.encoder - INFO - Loaded 3 sequences from /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/processed/hla_sequences.pkl\n",
      "2025-05-02 06:56:29,413 - src.models.encoder - INFO - No embedding cache found at /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/embeddings/hla_embeddings.pkl\n",
      "2025-05-02 06:56:29,414 - src.models.encoders.protbert - INFO - Auto-detected device: cpu\n",
      "2025-05-02 06:56:29,414 - src.models.encoders.protbert - INFO - Loading ProtBERT model: Rostlab/prot_bert\n",
      "2025-05-02 06:56:30,075 - src.models.encoders.protbert - INFO - Successfully loaded model on cpu\n",
      "ProtBERT model: Rostlab/prot_bert\n",
      "Pooling strategy: mean\n",
      "Using peptide binding region: True\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoder\n",
    "encoder = ProtBERTEncoder(\n",
    "    sequence_file=sequence_file,\n",
    "    cache_dir=embeddings_dir,\n",
    "    pooling_strategy=\"mean\",\n",
    "    use_peptide_binding_region=True\n",
    ")\n",
    "\n",
    "print(f\"ProtBERT model: {encoder.model_name}\")\n",
    "print(f\"Pooling strategy: {encoder.pooling_strategy}\")\n",
    "print(f\"Using peptide binding region: {encoder.use_peptide_binding_region}\")\n",
    "print(f\"Device: {encoder.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Available HLA Alleles\n",
    "\n",
    "Let's see what HLA alleles are available in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of alleles: 3\n",
      "Locus A: 2 alleles\n",
      "Locus B: 1 alleles\n",
      "\n",
      "Example A alleles: A*01:01, A*02:01\n",
      "\n",
      "Example B alleles: B*07:02\n",
      "\n",
      "Example C alleles: \n",
      "\n",
      "Example DRB1 alleles: \n"
     ]
    }
   ],
   "source": [
    "# Get allele counts by locus\n",
    "alleles = list(encoder.sequences.keys())\n",
    "print(f\"Total number of alleles: {len(alleles)}\")\n",
    "\n",
    "# Count alleles per locus\n",
    "locus_counts = {}\n",
    "for allele in alleles:\n",
    "    locus = allele.split('*')[0]\n",
    "    locus_counts[locus] = locus_counts.get(locus, 0) + 1\n",
    "\n",
    "# Display counts\n",
    "for locus, count in sorted(locus_counts.items()):\n",
    "    print(f\"Locus {locus}: {count} alleles\")\n",
    "\n",
    "# Show a few example alleles for common loci\n",
    "common_loci = ['A', 'B', 'C', 'DRB1']\n",
    "for locus in common_loci:\n",
    "    examples = [a for a in alleles if a.startswith(f\"{locus}*\")][:5]\n",
    "    print(f\"\\nExample {locus} alleles: {', '.join(examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Individual Alleles\n",
    "\n",
    "Now let's encode some individual HLA alleles and examine their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-02 06:56:30,660 - src.models.encoder - INFO - Saved 1 embeddings to /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/embeddings/hla_embeddings.pkl\n",
      "\n",
      "A*01:01:\n",
      "  Sequence: MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRFIAVG...\n",
      "  Sequence length: 366 amino acids\n",
      "  Embedding shape: (1024,)\n",
      "  Embedding stats: min=-0.5693, max=2.1139, mean=0.0017\n",
      "2025-05-02 06:56:31,180 - src.models.encoder - INFO - Saved 2 embeddings to /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/embeddings/hla_embeddings.pkl\n",
      "\n",
      "A*02:01:\n",
      "  Sequence: MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRFIAVG...\n",
      "  Sequence length: 367 amino acids\n",
      "  Embedding shape: (1024,)\n",
      "  Embedding stats: min=-0.5814, max=2.1299, mean=0.0017\n",
      "2025-05-02 06:56:31,683 - src.models.encoder - INFO - Saved 3 embeddings to /Users/dakdemir/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/data/embeddings/hla_embeddings.pkl\n",
      "\n",
      "B*07:02:\n",
      "  Sequence: MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTAMSRPGRGEPRFISVG...\n",
      "  Sequence length: 365 amino acids\n",
      "  Embedding shape: (1024,)\n",
      "  Embedding stats: min=-0.5130, max=2.0264, mean=0.0014\n",
      "2025-05-02 06:56:31,684 - src.models.encoder - WARNING - No sequence found for allele B*08:01\n",
      "No sequence found for B*08:01\n",
      "2025-05-02 06:56:31,684 - src.models.encoder - WARNING - No sequence found for allele C*07:01\n",
      "No sequence found for C*07:01\n"
     ]
    }
   ],
   "source": [
    "# Define some common alleles to encode\n",
    "test_alleles = [\"A*01:01\", \"A*02:01\", \"B*07:02\", \"B*08:01\", \"C*07:01\"]\n",
    "\n",
    "# Encode each allele\n",
    "embeddings = {}\n",
    "for allele in test_alleles:\n",
    "    try:\n",
    "        # Get protein sequence\n",
    "        sequence = encoder.get_sequence(allele)\n",
    "        if sequence is None:\n",
    "            print(f\"No sequence found for {allele}\")\n",
    "            continue\n",
    "        \n",
    "        # Get embedding\n",
    "        embedding = encoder.get_embedding(allele)\n",
    "        embeddings[allele] = embedding\n",
    "        \n",
    "        # Print info\n",
    "        print(f\"\\n{allele}:\")\n",
    "        print(f\"  Sequence: {sequence[:50]}...\" if len(sequence) > 50 else f\"  Sequence: {sequence}\")\n",
    "        print(f\"  Sequence length: {len(sequence)} amino acids\")\n",
    "        print(f\"  Embedding shape: {embedding.shape}\")\n",
    "        print(f\"  Embedding stats: min={embedding.min():.4f}, max={embedding.max():.4f}, mean={embedding.mean():.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding {allele}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similar Alleles\n",
    "\n",
    "One of the key features of HLA-ProtBERT is the ability to find similar alleles based on embedding similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alleles similar to A*01:01:\n",
      "  A*02:01: similarity=0.9993\n",
      "  B*07:02: similarity=0.9753\n",
      "\n",
      "Alleles similar to A*02:01:\n",
      "  A*01:01: similarity=0.9993\n",
      "  B*07:02: similarity=0.9720\n",
      "\n",
      "Alleles similar to B*07:02:\n",
      "  A*01:01: similarity=0.9753\n",
      "  A*02:01: similarity=0.9720\n"
     ]
    }
   ],
   "source": [
    "# Find similar alleles for each test allele\n",
    "for allele in test_alleles:\n",
    "    if allele not in embeddings:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nAlleles similar to {allele}:\")\n",
    "    similar = encoder.find_similar_alleles(allele, top_k=5)\n",
    "    \n",
    "    if not similar:\n",
    "        print(\"  No similar alleles found\")\n",
    "        continue\n",
    "        \n",
    "    for similar_allele, similarity in similar:\n",
    "        print(f\"  {similar_allele}: similarity={similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple Alleles\n",
    "\n",
    "Let's compare the similarity between different alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise similarities:\n",
      "  A*01:01 vs A*02:01: 0.9993\n",
      "    These alleles are identical or encode the same protein\n",
      "  A*01:01 vs B*07:02: 0.9753\n",
      "    These alleles are very similar (likely same protein group)\n",
      "  A*02:01 vs B*07:02: 0.9720\n",
      "    These alleles are very similar (likely same protein group)\n"
     ]
    }
   ],
   "source": [
    "# Compare alleles\n",
    "if len(embeddings) > 1:\n",
    "    print(\"Pairwise similarities:\")\n",
    "    \n",
    "    allele_list = list(embeddings.keys())\n",
    "    for i, allele1 in enumerate(allele_list):\n",
    "        for allele2 in allele_list[i+1:]:\n",
    "            # Calculate cosine similarity\n",
    "            similarity = encoder._cosine_similarity(embeddings[allele1], embeddings[allele2])\n",
    "            print(f\"  {allele1} vs {allele2}: {similarity:.4f}\")\n",
    "            \n",
    "            # Interpret similarity\n",
    "            if similarity > 0.99:\n",
    "                print(f\"    These alleles are identical or encode the same protein\")\n",
    "            elif similarity > 0.95:\n",
    "                print(f\"    These alleles are very similar (likely same protein group)\")\n",
    "            elif similarity > 0.90:\n",
    "                print(f\"    These alleles are functionally similar\")\n",
    "            elif similarity < 0.70:\n",
    "                print(f\"    These alleles are substantially different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Embeddings\n",
    "\n",
    "Let's visualize the embeddings to get a better understanding of the relationships between alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got embeddings for 2 A alleles\n",
      "Got embeddings for 1 B alleles\n",
      "Got embeddings for 0 C alleles\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for specific loci\n",
    "loci_to_visualize = ['A', 'B', 'C']\n",
    "loci_alleles = {}\n",
    "loci_embeddings = {}\n",
    "\n",
    "for locus in loci_to_visualize:\n",
    "    # Get alleles for this locus\n",
    "    locus_alleles = [a for a in alleles if a.startswith(f\"{locus}*\")][:20]  # Limit to 20 alleles per locus\n",
    "    loci_alleles[locus] = locus_alleles\n",
    "    \n",
    "    # Get embeddings\n",
    "    locus_embeddings = [encoder.get_embedding(a) for a in locus_alleles]\n",
    "    loci_embeddings[locus] = np.array(locus_embeddings)\n",
    "    \n",
    "    print(f\"Got embeddings for {len(locus_alleles)} {locus} alleles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1024 and the array at index 2 has size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Combine all embeddings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloci_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlocus\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlocus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloci_to_visualize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m locus \u001b[38;5;129;01min\u001b[39;00m loci_to_visualize:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-NMDP/Year2025/Github/hla-protbert/venv/lib/python3.10/site-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1024 and the array at index 2 has size 0"
     ]
    }
   ],
   "source": [
    "# Use PCA to reduce dimensions for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Combine all embeddings\n",
    "all_embeddings = np.vstack([loci_embeddings[locus] for locus in loci_to_visualize])\n",
    "all_labels = []\n",
    "for locus in loci_to_visualize:\n",
    "    all_labels.extend([locus] * len(loci_alleles[locus]))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = {'A': 'blue', 'B': 'red', 'C': 'green'}\n",
    "\n",
    "for locus in loci_to_visualize:\n",
    "    indices = [i for i, label in enumerate(all_labels) if label == locus]\n",
    "    plt.scatter(\n",
    "        reduced_embeddings[indices, 0], \n",
    "        reduced_embeddings[indices, 1],\n",
    "        color=colors[locus],\n",
    "        label=f\"HLA-{locus}\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.title(\"PCA Visualization of HLA Allele Embeddings\")\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%})\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%})\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Similarity Between Common Alleles\n",
    "\n",
    "Let's create a heatmap to visualize similarity between common alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common alleles for similarity matrix\n",
    "common_alleles = [\n",
    "    \"A*01:01\", \"A*02:01\", \"A*03:01\", \"A*24:02\",\n",
    "    \"B*07:02\", \"B*08:01\", \"B*15:01\", \"B*27:05\",\n",
    "    \"C*01:02\", \"C*03:04\", \"C*07:01\", \"C*07:02\"\n",
    "]\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = np.zeros((len(common_alleles), len(common_alleles)))\n",
    "valid_alleles = []\n",
    "\n",
    "for i, allele1 in enumerate(common_alleles):\n",
    "    try:\n",
    "        embedding1 = encoder.get_embedding(allele1)\n",
    "        valid_alleles.append(allele1)\n",
    "        \n",
    "        for j, allele2 in enumerate(common_alleles):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 1.0  # Self-similarity\n",
    "            elif j < i:\n",
    "                similarity_matrix[i, j] = similarity_matrix[j, i]  # Symmetric\n",
    "            else:\n",
    "                try:\n",
    "                    embedding2 = encoder.get_embedding(allele2)\n",
    "                    similarity = encoder._cosine_similarity(embedding1, embedding2)\n",
    "                    similarity_matrix[i, j] = similarity\n",
    "                except Exception:\n",
    "                    similarity_matrix[i, j] = np.nan\n",
    "    except Exception:\n",
    "        # Skip alleles that can't be encoded\n",
    "        print(f\"Skipping {allele1} - could not get embedding\")\n",
    "        continue\n",
    "\n",
    "# Plot heatmap\n",
    "if valid_alleles:  # Only plot if we have valid alleles\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix[:len(valid_alleles), :len(valid_alleles)],\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"viridis\",\n",
    "        xticklabels=valid_alleles,\n",
    "        yticklabels=valid_alleles,\n",
    "        cbar_kws={\"label\": \"Cosine Similarity\"}\n",
    "    )\n",
    "    plt.title(\"Similarity Between Common HLA Alleles\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Use Case: Donor-Recipient Matching\n",
    "\n",
    "Let's demonstrate a practical use case of HLA-ProtBERT for donor-recipient matching in transplantation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define donor and recipient HLA types\n",
    "donor = {\n",
    "    \"A\": [\"A*01:01\", \"A*02:01\"],\n",
    "    \"B\": [\"B*07:02\", \"B*08:01\"],\n",
    "    \"C\": [\"C*07:01\", \"C*07:02\"]\n",
    "}\n",
    "\n",
    "recipient = {\n",
    "    \"A\": [\"A*01:01\", \"A*24:02\"],\n",
    "    \"B\": [\"B*07:02\", \"B*15:01\"],\n",
    "    \"C\": [\"C*03:04\", \"C*07:01\"]\n",
    "}\n",
    "\n",
    "# Function to calculate match score\n",
    "def calculate_match_score(donor, recipient, encoder):\n",
    "    match_scores = {}\n",
    "    overall_match = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for locus in donor.keys():\n",
    "        locus_scores = []\n",
    "        \n",
    "        for d_allele in donor[locus]:\n",
    "            for r_allele in recipient[locus]:\n",
    "                try:\n",
    "                    # Get embeddings\n",
    "                    d_embedding = encoder.get_embedding(d_allele)\n",
    "                    r_embedding = encoder.get_embedding(r_allele)\n",
    "                    \n",
    "                    # Calculate similarity\n",
    "                    similarity = encoder._cosine_similarity(d_embedding, r_embedding)\n",
    "                    locus_scores.append((d_allele, r_allele, similarity))\n",
    "                    \n",
    "                    overall_match += similarity\n",
    "                    count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error comparing {d_allele} and {r_allele}: {e}\")\n",
    "        \n",
    "        match_scores[locus] = locus_scores\n",
    "    \n",
    "    # Calculate average match score\n",
    "    avg_match = overall_match / count if count > 0 else 0.0\n",
    "    \n",
    "    return match_scores, avg_match\n",
    "\n",
    "# Calculate match score\n",
    "match_scores, avg_match = calculate_match_score(donor, recipient, encoder)\n",
    "\n",
    "# Print results\n",
    "print(f\"Donor-Recipient HLA Match Analysis\")\n",
    "print(f\"Overall Match Score: {avg_match:.4f}\\n\")\n",
    "\n",
    "for locus, scores in match_scores.items():\n",
    "    print(f\"HLA-{locus} Matching:\")\n",
    "    for d_allele, r_allele, similarity in scores:\n",
    "        match_quality = \"Exact match\" if similarity > 0.99 else \\\n",
    "                       \"Very close match\" if similarity > 0.95 else \\\n",
    "                       \"Functional match\" if similarity > 0.90 else \\\n",
    "                       \"Partial match\" if similarity > 0.80 else \\\n",
    "                       \"Mismatch\"\n",
    "        print(f\"  {d_allele} vs {r_allele}: {similarity:.4f} ({match_quality})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the HLA-ProtBERT library to:\n",
    "\n",
    "1. Encode HLA alleles into high-dimensional protein embeddings\n",
    "2. Find similar alleles based on embedding similarity\n",
    "3. Compare multiple alleles\n",
    "4. Visualize embeddings using dimensionality reduction\n",
    "5. Perform donor-recipient matching analysis\n",
    "\n",
    "These embeddings can be used for various downstream tasks such as:\n",
    "- Clinical outcome prediction\n",
    "- Donor-recipient matching optimization\n",
    "- Studying HLA structure-function relationships\n",
    "- Understanding HLA compatibility beyond traditional matching criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
